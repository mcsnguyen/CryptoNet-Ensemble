{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, AveragePooling2D, MaxPooling2D, Dense, Flatten\n",
    "from keras import layers, backend, utils, optimizers, datasets\n",
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = 'MNIST-28x28-train.txt'\n",
    "test_input_path = 'MNIST-28x28-test.txt'\n",
    "preprocessed_input_path = 'Preprocessed-MNIST-train_test.npz'\n",
    "model_dir = 'ReLU/' \n",
    "weight_path = ''\n",
    "train_dataset_size = 60000\n",
    "test_dataset_size = 10000\n",
    "image_size = 784  # 28 x 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "def MNIST_reader(input_name, data_size_num, image_size_num):\n",
    "    content = []\n",
    "    with open(input_name, 'r') as file:\n",
    "        for line in file:\n",
    "            content.append(line)\n",
    "\n",
    "    input_pixels = np.zeros([data_size_num, image_size_num])\n",
    "    labels = np.zeros([data_size_num])\n",
    "\n",
    "    for image in range(0, len(content)):\n",
    "        coordinates = np.asarray(content[image].split('\\t'))\n",
    "        for coordinate in coordinates[2:]:\n",
    "            if coordinate == '':\n",
    "                break\n",
    "            pair = coordinate.split(':')\n",
    "            input_pixels[image, int(pair[0])] = pair[1]\n",
    "            labels[image] = coordinates[0]\n",
    "    \n",
    "    return input_pixels, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1,
     10,
     50,
     53,
     58,
     72,
     84,
     102,
     118
    ]
   },
   "outputs": [],
   "source": [
    "# Upper and lower padding\n",
    "def ULpadding(data_list):\n",
    "    padded = []\n",
    "    for dataset in data_list:\n",
    "        reshaped = dataset.reshape(dataset.shape[0], 28, 28, 1)\n",
    "        padded_reshaped = np.insert(reshaped, 0, 0, axis=1)\n",
    "        padded.append(np.insert(padded_reshaped, 0, 0, axis=2)/255)\n",
    "    return (*padded,)\n",
    "\n",
    "# Converts integer labels to one hot encoding\n",
    "def one_hot(label_list):\n",
    "    encoded = []\n",
    "    for label in label_list:\n",
    "        encoded.append(utils.to_categorical(label))\n",
    "    return (*encoded,)\n",
    "\n",
    "# CryptoNet's Testing Network\n",
    "def Simplified_CryptoNet(input_size, custom):\n",
    "    input_shape = Input(shape=(input_size))\n",
    "    if custom:\n",
    "        conv1 = Conv2D(filters=5, kernel_size=(5,5), strides=(2,2), activation=approxReLU)(input_shape)\n",
    "    else:\n",
    "        conv1 = Conv2D(filters=5, kernel_size=(5,5), strides=(2,2), activation='relu')(input_shape)\n",
    "    \n",
    "    flat = Flatten()(conv1) \n",
    "    \n",
    "    if custom:\n",
    "        dense = Dense(100, activation=approxReLU)(flat)\n",
    "    else:\n",
    "        dense = Dense(100, activation='relu')(flat)\n",
    "        \n",
    "    output_shape = Dense(10, activation='softmax')(dense)\n",
    "    \n",
    "    model = Model(inputs=input_shape, outputs=output_shape)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def approxReLU(x):\n",
    "    return 0.125*x**2 + 0.25*x + 0.5\n",
    "    #return 0.1997*x**2 + 0.5002*x + 0.1992\n",
    "\n",
    "def squared(x):\n",
    "    return x**2\n",
    "\n",
    "def train(model, train_images, train_labels, epoch=10, val_split=0.2, **kwargs):\n",
    "    sgd = optimizers.SGD(lr=0.0095)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['acc'])\n",
    "    model.fit(x=train_images, y=train_labels, epochs=epoch, verbose=1, validation_split=val_split)\n",
    "\n",
    "def avg_ensemble(predicted1, predicted2, predicted3):\n",
    "    return (predicted1 + predicted2 + predicted3)/3\n",
    "\n",
    "def max_ensemble(predicted1, predicted2, predicted3):\n",
    "    maximum = np.maximum(predicted1, predicted2)\n",
    "    return np.maximum(maximum, predicted3)\n",
    "\n",
    "# Splits same training for testing\n",
    "def with_train_data(data_list, label_list):\n",
    "    train_x1, test_x1, train_y1, test_y1 = train_test_split(datalist[1], label_list[1], test_size=0.2)\n",
    "    train_x2, test_x2, train_y2, test_y2 = train_test_split(datalist[2], label_list[2], test_size=0.2)\n",
    "    train_x3, test_x3, train_y3, test_y3 = train_test_split(datalist[3], label_list[3], test_size=0.2)\n",
    "\n",
    "    test_images = np.concatenate(test_x1, test_x2, test_x3, axis=0)\n",
    "    test_labels = np.concatenate(test_y1, test_y2, test_y3, axis=0)\n",
    "    \n",
    "    train_list = [data_list[0], train_x1, train_x2, train_x3, test_images]\n",
    "    labels_list = [label_list[0], train_y1, train_y2, train_y3, test_labels]\n",
    "    \n",
    "    return with_train_and_test_data(train_list, labels_list)\n",
    "\n",
    "# Uses different sets for training and testing\n",
    "def with_train_and_test_data(data_list, label_list, epoch):\n",
    "    whole_train, train_x1, train_x2, train_x3, test_images = ULpadding(data_list)\n",
    "    whole_label, train_y1, train_y2, train_y3, test_labels = one_hot(label_list)\n",
    "    \n",
    "    train_list = [whole_train, train_x1, train_x2, train_x3, test_images]\n",
    "    labels_list = [whole_label, train_y1, train_y2, train_y3, test_labels]\n",
    "    epoch_list = epoch_ratios(epoch, train_list) \n",
    "    \n",
    "    return epoch_list, train_list, labels_list\n",
    "    \n",
    "# Creates ratios for epoch such that smaller datasets are traversed \n",
    "# more than larger datasets to compensate\n",
    "def epoch_ratios(epoch, train_shapes):\n",
    "    ratio_list = []\n",
    "    \n",
    "    whole_shape = train_shapes[0].shape[0]\n",
    "    \n",
    "    ratio1 = whole_shape/train_shapes[1].shape[0]\n",
    "    ratio2 = whole_shape/train_shapes[2].shape[0]\n",
    "    ratio3 = whole_shape/train_shapes[3].shape[0]\n",
    "    \n",
    "    epoch_whole = epoch\n",
    "    \n",
    "    ratio_list.append(epoch_whole) # whole dataset\n",
    "    ratio_list.append(int(ratio1 * epoch_whole)) # model 1\n",
    "    ratio_list.append(int(ratio2 * epoch_whole)) # model 2\n",
    "    ratio_list.append(int(ratio3 * epoch_whole)) # model 3\n",
    "    \n",
    "    return ratio_list   \n",
    "\n",
    "def train_dataset(epoch_list, img_list, label_list, custom=False):\n",
    "    # Whole Dataset\n",
    "    model = Simplified_CryptoNet(img_list[0].shape[1:], custom)\n",
    "    train(model, img_list[0], label_list[0], epoch=epoch_list[0])\n",
    "\n",
    "    # Ensemble\n",
    "    model1 = Simplified_CryptoNet(img_list[1].shape[1:], custom)\n",
    "    model2 = Simplified_CryptoNet(img_list[2].shape[1:], custom)\n",
    "    model3 = Simplified_CryptoNet(img_list[3].shape[1:], custom)\n",
    "\n",
    "    train(model1, img_list[1], label_list[1], epoch=epoch_list[1])\n",
    "    train(model2, img_list[2], label_list[2], epoch=epoch_list[2])\n",
    "    train(model3, img_list[3], label_list[3], epoch=epoch_list[3])\n",
    "    \n",
    "    return model, model1, model2, model3\n",
    "\n",
    "def accuracy_test(model_list, test_img, test_label):\n",
    "    whole_acc = 0\n",
    "    avg_ensemble_acc = 0\n",
    "    max_ensemble_acc = 0\n",
    "    model1_acc = 0\n",
    "    model2_acc = 0\n",
    "    model3_acc = 0\n",
    "\n",
    "    whole = model_list[0].predict(test_img)\n",
    "    predict1 = model_list[1].predict(test_img)\n",
    "    predict2 = model_list[2].predict(test_img)\n",
    "    predict3 = model_list[3].predict(test_img)\n",
    "\n",
    "    avg = avg_ensemble(predict1, predict2, predict3)\n",
    "    maximum = max_ensemble(predict1, predict2, predict3)  \n",
    "    \n",
    "    true_label = np.argmax(test_label, axis=1)\n",
    "    whole_label = np.argmax(whole, axis=1)\n",
    "    avg_label = np.argmax(avg, axis=1)\n",
    "    max_label = np.argmax(maximum, axis=1)\n",
    "    model1 = np.argmax(predict1, axis=1)\n",
    "    model2 = np.argmax(predict2, axis=1)\n",
    "    model3 = np.argmax(predict3, axis=1)\n",
    "    \n",
    "    for index in range(0, test_img.shape[0]):\n",
    "        if whole_label[index] == true_label[index]:\n",
    "            whole_acc += 1\n",
    "        if avg_label[index] == true_label[index]:\n",
    "            avg_ensemble_acc += 1\n",
    "        if max_label[index] == true_label[index]:\n",
    "            max_ensemble_acc += 1\n",
    "        if model1[index] == true_label[index]:\n",
    "            model1_acc += 1\n",
    "        if model2[index] == true_label[index]:\n",
    "            model2_acc += 1\n",
    "        if model3[index] == true_label[index]:\n",
    "            model3_acc += 1\n",
    "    \n",
    "    return test_img.shape[0], whole_acc, avg_ensemble_acc, max_ensemble_acc, model1_acc, model2_acc, model3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Read in input\n",
    "train_input_pixels, train_labels = MNIST_reader(train_input_path, train_dataset_size, image_size)\n",
    "test_input_pixels, test_labels = MNIST_reader(test_input_path, test_dataset_size, image_size)\n",
    "\n",
    "np.savez(preprocessed_input_path, train_img=train_input_pixels, train_lab=train_labels,\n",
    "        test_img=test_input_pixels, test_lab=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load in saved preprocessed np arrays\n",
    "with np.load(preprocessed_input_path, 'r') as preprocessed:\n",
    "    train_input_pixels = preprocessed['train_img']\n",
    "    train_labels = preprocessed['train_lab']\n",
    "    test_input_pixels = preprocessed['test_img']\n",
    "    test_labels = preprocessed['test_lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n"
     ]
    }
   ],
   "source": [
    "# MNIST Training Splicing\n",
    "zero_images = []\n",
    "zero_labels = []\n",
    "one_images = []\n",
    "one_labels = []\n",
    "two_images = []\n",
    "two_labels = []\n",
    "three_images = []\n",
    "three_labels = []\n",
    "four_images = []\n",
    "four_labels = []\n",
    "five_images = []\n",
    "five_labels = []\n",
    "six_images = []\n",
    "six_labels = []\n",
    "seven_images = []\n",
    "seven_labels = []\n",
    "eight_images = []\n",
    "eight_labels = []\n",
    "nine_images = []\n",
    "nine_labels = []\n",
    "\n",
    "zero = []\n",
    "one = []\n",
    "two = []\n",
    "three = []\n",
    "four = []\n",
    "five = []\n",
    "six = []\n",
    "seven = []\n",
    "eight = []\n",
    "nine = []\n",
    "\n",
    "for idx in range(train_dataset_size):\n",
    "    if train_labels[idx] == 0:\n",
    "        zero_images.append(train_input_pixels[idx])\n",
    "        zero_labels.append(train_labels[idx])\n",
    "        zero.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 1:\n",
    "        one_images.append(train_input_pixels[idx])\n",
    "        one_labels.append(train_labels[idx])\n",
    "        one.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 2:\n",
    "        two_images.append(train_input_pixels[idx])\n",
    "        two_labels.append(train_labels[idx])\n",
    "        two.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 3:\n",
    "        three_images.append(train_input_pixels[idx])\n",
    "        three_labels.append(train_labels[idx])\n",
    "        three.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 4:\n",
    "        four_images.append(train_input_pixels[idx])\n",
    "        four_labels.append(train_labels[idx])\n",
    "        four.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 5:\n",
    "        five_images.append(train_input_pixels[idx])\n",
    "        five_labels.append(train_labels[idx])\n",
    "        five.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 6:\n",
    "        six_images.append(train_input_pixels[idx])\n",
    "        six_labels.append(train_labels[idx])\n",
    "        six.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 7:\n",
    "        seven_images.append(train_input_pixels[idx])\n",
    "        seven_labels.append(train_labels[idx])\n",
    "        seven.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    elif train_labels[idx] == 8:\n",
    "        eight_images.append(train_input_pixels[idx])\n",
    "        eight_labels.append(train_labels[idx])\n",
    "        eight.append((train_input_pixels[idx],train_labels[idx]))\n",
    "    else:\n",
    "        nine_images.append(train_input_pixels[idx])\n",
    "        nine_labels.append(train_labels[idx])\n",
    "        nine.append((train_input_pixels[idx],train_labels[idx]))\n",
    "\n",
    "num = [len(zero), len(one), len(two), len(three), len(four), len(five), len(six), len(seven), len(eight), len(nine)]\n",
    "print(num)\n",
    "\n",
    "dataset1_images = []\n",
    "dataset1_labels = []\n",
    "dataset2_images = []\n",
    "dataset2_labels = []\n",
    "dataset3_images = []\n",
    "dataset3_labels = []\n",
    "\n",
    "dataset1_images += zero_images[:5000]\n",
    "dataset1_images += one_images[:5000]\n",
    "dataset1_images += two_images[:5000]\n",
    "dataset1_images += three_images[:250]\n",
    "dataset1_images += four_images[:250]\n",
    "dataset1_images += five_images[:150]\n",
    "dataset1_images += six_images[:250]\n",
    "dataset1_images += seven_images[:250]\n",
    "dataset1_images += eight_images[:250]\n",
    "dataset1_images += nine_images[:250]\n",
    "\n",
    "dataset1_labels += zero_labels[:5000]\n",
    "dataset1_labels += one_labels[:5000]\n",
    "dataset1_labels += two_labels[:5000]\n",
    "dataset1_labels += three_labels[:250]\n",
    "dataset1_labels += four_labels[:250]\n",
    "dataset1_labels += five_labels[:150]\n",
    "dataset1_labels += six_labels[:250]\n",
    "dataset1_labels += seven_labels[:250]\n",
    "dataset1_labels += eight_labels[:250]\n",
    "dataset1_labels += nine_labels[:250]\n",
    "\n",
    "dataset2_images += zero_images[5000:5250]\n",
    "dataset2_images += one_images[5000:5250]\n",
    "dataset2_images += two_images[5000:5250]\n",
    "dataset2_images += three_images[250:5250]\n",
    "dataset2_images += four_images[250:5250]\n",
    "dataset2_images += five_images[150:5021]\n",
    "dataset2_images += six_images[250:500]\n",
    "dataset2_images += seven_images[250:500]\n",
    "dataset2_images += eight_images[250:500]\n",
    "dataset2_images += nine_images[250:500]\n",
    "\n",
    "dataset2_labels += zero_labels[5000:5250]\n",
    "dataset2_labels += one_labels[5000:5250]\n",
    "dataset2_labels += two_labels[5000:5250]\n",
    "dataset2_labels += three_labels[250:5250]\n",
    "dataset2_labels += four_labels[250:5250]\n",
    "dataset2_labels += five_labels[150:5021]\n",
    "dataset2_labels += six_labels[250:500]\n",
    "dataset2_labels += seven_labels[250:500]\n",
    "dataset2_labels += eight_labels[250:500]\n",
    "dataset2_labels += nine_labels[250:500]\n",
    "\n",
    "dataset3_images += zero_images[5250:]\n",
    "dataset3_images += one_images[5250:5950]\n",
    "dataset3_images += two_images[5250:5950]\n",
    "dataset3_images += three_images[5250:5950]\n",
    "dataset3_images += four_images[5250:]\n",
    "dataset3_images += five_images[5021:]\n",
    "dataset3_images += six_images[500:4300]\n",
    "dataset3_images += seven_images[500:4300]\n",
    "dataset3_images += eight_images[500:4300]\n",
    "dataset3_images += nine_images[500:4300]\n",
    "\n",
    "dataset3_labels += zero_labels[5250:]\n",
    "dataset3_labels += one_labels[5250:5950]\n",
    "dataset3_labels += two_labels[5250:5950]\n",
    "dataset3_labels += three_labels[5250:5950]\n",
    "dataset3_labels += four_labels[5250:]\n",
    "dataset3_labels += five_labels[5021:]\n",
    "dataset3_labels += six_labels[500:4300]\n",
    "dataset3_labels += seven_labels[500:4300]\n",
    "dataset3_labels += eight_labels[500:4300]\n",
    "dataset3_labels += nine_labels[500:4300]\n",
    "\n",
    "combined1 = list(zip(dataset1_images, dataset1_labels))\n",
    "combined2 = list(zip(dataset2_images, dataset2_labels))\n",
    "combined3 = list(zip(dataset3_images, dataset3_labels))\n",
    "\n",
    "random.shuffle(combined1)\n",
    "random.shuffle(combined2)\n",
    "random.shuffle(combined3)\n",
    "\n",
    "dataset1_images[:], dataset1_labels[:] = zip(*combined1)\n",
    "dataset2_images[:], dataset2_labels[:] = zip(*combined2)\n",
    "dataset3_images[:], dataset3_labels[:] = zip(*combined3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     3,
     11
    ]
   },
   "outputs": [],
   "source": [
    "# Preprocess and group data and label\n",
    "'''\n",
    "# Lists to Split Training for Testing\n",
    "data_list = [np.asarray(train_input_pixels), np.asarray(dataset1_images), np.asarray(dataset2_images),\n",
    "             np.asarray(dataset3_images)]\n",
    "label_list = [train_labels, dataset1_labels, dataset2_labels, dataset3_labels]\n",
    "\n",
    "epoch_list, train_list, label_list = with_train_data(data_list, label_list)\n",
    "'''\n",
    "\n",
    "# Lists with Training and Testing Available\n",
    "data_list = [np.asarray(train_input_pixels), np.asarray(dataset1_images), np.asarray(dataset2_images),\n",
    "             np.asarray(dataset3_images), np.asarray(test_input_pixels)]\n",
    "label_list = [train_labels, dataset1_labels, dataset2_labels, dataset3_labels, test_labels]\n",
    "\n",
    "# Add preprocessed epochs, padded, one hot encoded into lists\n",
    "# 3rd arg is epoch for whole dataset\n",
    "epoch_list, train_list, label_list = with_train_and_test_data(data_list, label_list, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load in trained model\n",
    "model_list = [] \n",
    "model_list.append(load_model(model_dir + 'model_whole-0.01LR.h5', custom_objects={'approxReLU': approxReLU}))\n",
    "model_list.append(load_model(model_dir + 'model1-0.01LR.h5', custom_objects={'approxReLU': approxReLU}))\n",
    "model_list.append(load_model(model_dir + 'model2-0.01LR.h5', custom_objects={'approxReLU': approxReLU}))\n",
    "model_list.append(load_model(model_dir + 'model3-0.01LR.h5', custom_objects={'approxReLU': approxReLU}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0728 20:47:32.749178 24024 deprecation_wrapper.py:119] From C:\\Users\\PandaBear\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0728 20:47:32.761177 24024 deprecation_wrapper.py:119] From C:\\Users\\PandaBear\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0728 20:47:32.763180 24024 deprecation_wrapper.py:119] From C:\\Users\\PandaBear\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0728 20:47:32.825179 24024 deprecation_wrapper.py:119] From C:\\Users\\PandaBear\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0728 20:47:32.833178 24024 deprecation_wrapper.py:119] From C:\\Users\\PandaBear\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0728 20:47:32.924176 24024 deprecation.py:323] From C:\\Users\\PandaBear\\Anaconda3\\envs\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0728 20:47:32.970178 24024 deprecation_wrapper.py:119] From C:\\Users\\PandaBear\\Anaconda3\\envs\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 29, 29, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 5)         130       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 845)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               84600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 85,740\n",
      "Trainable params: 85,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.6357 - acc: 0.8124 - val_loss: 0.2758 - val_acc: 0.9190\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 7s 145us/step - loss: 0.2581 - acc: 0.9236 - val_loss: 0.2178 - val_acc: 0.9385\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.2056 - acc: 0.9392 - val_loss: 0.1776 - val_acc: 0.9496\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1703 - acc: 0.9494 - val_loss: 0.1571 - val_acc: 0.9547\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1483 - acc: 0.9557 - val_loss: 0.1467 - val_acc: 0.9567\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1317 - acc: 0.9609 - val_loss: 0.1235 - val_acc: 0.9643\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1185 - acc: 0.9641 - val_loss: 0.1220 - val_acc: 0.9634\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1080 - acc: 0.9665 - val_loss: 0.1148 - val_acc: 0.9647\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.0989 - acc: 0.9699 - val_loss: 0.1146 - val_acc: 0.9648\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.0922 - acc: 0.9714 - val_loss: 0.1000 - val_acc: 0.9696\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 29, 29, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 5)         130       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 845)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               84600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 85,740\n",
      "Trainable params: 85,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 29, 29, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 5)         130       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 845)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               84600     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 85,740\n",
      "Trainable params: 85,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 29, 29, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 5)         130       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 845)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               84600     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 85,740\n",
      "Trainable params: 85,740\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13320 samples, validate on 3330 samples\n",
      "Epoch 1/36\n",
      "13320/13320 [==============================] - 2s 167us/step - loss: 0.6154 - acc: 0.8417 - val_loss: 0.3232 - val_acc: 0.9054\n",
      "Epoch 2/36\n",
      "13320/13320 [==============================] - 2s 148us/step - loss: 0.2495 - acc: 0.9306 - val_loss: 0.2262 - val_acc: 0.9354\n",
      "Epoch 3/36\n",
      "13320/13320 [==============================] - 2s 149us/step - loss: 0.1858 - acc: 0.9486 - val_loss: 0.2006 - val_acc: 0.9420\n",
      "Epoch 4/36\n",
      "13320/13320 [==============================] - 2s 115us/step - loss: 0.1566 - acc: 0.9565 - val_loss: 0.1616 - val_acc: 0.9538\n",
      "Epoch 5/36\n",
      "13320/13320 [==============================] - 1s 104us/step - loss: 0.1387 - acc: 0.9600 - val_loss: 0.1495 - val_acc: 0.9589\n",
      "Epoch 6/36\n",
      "13320/13320 [==============================] - 1s 104us/step - loss: 0.1253 - acc: 0.9640 - val_loss: 0.1403 - val_acc: 0.9631\n",
      "Epoch 7/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.1155 - acc: 0.9671 - val_loss: 0.1294 - val_acc: 0.9646\n",
      "Epoch 8/36\n",
      "13320/13320 [==============================] - 1s 104us/step - loss: 0.1069 - acc: 0.9694 - val_loss: 0.1293 - val_acc: 0.9637\n",
      "Epoch 9/36\n",
      "13320/13320 [==============================] - 1s 109us/step - loss: 0.1003 - acc: 0.9700 - val_loss: 0.1213 - val_acc: 0.9688\n",
      "Epoch 10/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0936 - acc: 0.9722 - val_loss: 0.1286 - val_acc: 0.9658\n",
      "Epoch 11/36\n",
      "13320/13320 [==============================] - 1s 106us/step - loss: 0.0886 - acc: 0.9741 - val_loss: 0.1179 - val_acc: 0.9670\n",
      "Epoch 12/36\n",
      "13320/13320 [==============================] - 1s 104us/step - loss: 0.0833 - acc: 0.9758 - val_loss: 0.1072 - val_acc: 0.9724\n",
      "Epoch 13/36\n",
      "13320/13320 [==============================] - 1s 106us/step - loss: 0.0792 - acc: 0.9773 - val_loss: 0.1082 - val_acc: 0.9715\n",
      "Epoch 14/36\n",
      "13320/13320 [==============================] - 1s 106us/step - loss: 0.0764 - acc: 0.9782 - val_loss: 0.1069 - val_acc: 0.9736\n",
      "Epoch 15/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0723 - acc: 0.9794 - val_loss: 0.1113 - val_acc: 0.9712\n",
      "Epoch 16/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0701 - acc: 0.9800 - val_loss: 0.0998 - val_acc: 0.9742\n",
      "Epoch 17/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0667 - acc: 0.9811 - val_loss: 0.0940 - val_acc: 0.9775\n",
      "Epoch 18/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0631 - acc: 0.9814 - val_loss: 0.0992 - val_acc: 0.9766\n",
      "Epoch 19/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0603 - acc: 0.9821 - val_loss: 0.1011 - val_acc: 0.9763\n",
      "Epoch 20/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0592 - acc: 0.9835 - val_loss: 0.0923 - val_acc: 0.9775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/36\n",
      "13320/13320 [==============================] - 1s 104us/step - loss: 0.0557 - acc: 0.9845 - val_loss: 0.0987 - val_acc: 0.9787\n",
      "Epoch 22/36\n",
      "13320/13320 [==============================] - 2s 128us/step - loss: 0.0541 - acc: 0.9848 - val_loss: 0.1020 - val_acc: 0.9757\n",
      "Epoch 23/36\n",
      "13320/13320 [==============================] - 2s 122us/step - loss: 0.0522 - acc: 0.9854 - val_loss: 0.0914 - val_acc: 0.9784\n",
      "Epoch 24/36\n",
      "13320/13320 [==============================] - 1s 110us/step - loss: 0.0497 - acc: 0.9864 - val_loss: 0.0897 - val_acc: 0.9796\n",
      "Epoch 25/36\n",
      "13320/13320 [==============================] - 1s 106us/step - loss: 0.0486 - acc: 0.9860 - val_loss: 0.0887 - val_acc: 0.9763\n",
      "Epoch 26/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0461 - acc: 0.9875 - val_loss: 0.0883 - val_acc: 0.9811\n",
      "Epoch 27/36\n",
      "13320/13320 [==============================] - 1s 109us/step - loss: 0.0442 - acc: 0.9884 - val_loss: 0.0869 - val_acc: 0.9805\n",
      "Epoch 28/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0427 - acc: 0.9884 - val_loss: 0.0908 - val_acc: 0.9784\n",
      "Epoch 29/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0420 - acc: 0.9884 - val_loss: 0.0919 - val_acc: 0.9778\n",
      "Epoch 30/36\n",
      "13320/13320 [==============================] - 1s 105us/step - loss: 0.0398 - acc: 0.9889 - val_loss: 0.0862 - val_acc: 0.9805\n",
      "Epoch 31/36\n",
      "13320/13320 [==============================] - 1s 104us/step - loss: 0.0391 - acc: 0.9885 - val_loss: 0.0881 - val_acc: 0.9805\n",
      "Epoch 32/36\n",
      "13320/13320 [==============================] - 2s 113us/step - loss: 0.0367 - acc: 0.9903 - val_loss: 0.0878 - val_acc: 0.9805\n",
      "Epoch 33/36\n",
      "13320/13320 [==============================] - 2s 130us/step - loss: 0.0363 - acc: 0.9898 - val_loss: 0.0891 - val_acc: 0.9796\n",
      "Epoch 34/36\n",
      "13320/13320 [==============================] - 2s 113us/step - loss: 0.0352 - acc: 0.9908 - val_loss: 0.0834 - val_acc: 0.9802\n",
      "Epoch 35/36\n",
      "13320/13320 [==============================] - 1s 104us/step - loss: 0.0338 - acc: 0.9908 - val_loss: 0.0851 - val_acc: 0.9826\n",
      "Epoch 36/36\n",
      "13320/13320 [==============================] - 1s 106us/step - loss: 0.0321 - acc: 0.9918 - val_loss: 0.0873 - val_acc: 0.9805\n",
      "Train on 13296 samples, validate on 3325 samples\n",
      "Epoch 1/36\n",
      "13296/13296 [==============================] - 2s 116us/step - loss: 0.7325 - acc: 0.8007 - val_loss: 0.4150 - val_acc: 0.8647\n",
      "Epoch 2/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.3172 - acc: 0.9020 - val_loss: 0.2607 - val_acc: 0.9242\n",
      "Epoch 3/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.2416 - acc: 0.9252 - val_loss: 0.2112 - val_acc: 0.9371\n",
      "Epoch 4/36\n",
      "13296/13296 [==============================] - 1s 110us/step - loss: 0.2037 - acc: 0.9379 - val_loss: 0.2211 - val_acc: 0.9308\n",
      "Epoch 5/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.1800 - acc: 0.9452 - val_loss: 0.1750 - val_acc: 0.9453\n",
      "Epoch 6/36\n",
      "13296/13296 [==============================] - 1s 101us/step - loss: 0.1631 - acc: 0.9500 - val_loss: 0.1537 - val_acc: 0.9525\n",
      "Epoch 7/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.1501 - acc: 0.9547 - val_loss: 0.1466 - val_acc: 0.9516\n",
      "Epoch 8/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.1389 - acc: 0.9567 - val_loss: 0.1289 - val_acc: 0.9561\n",
      "Epoch 9/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.1284 - acc: 0.9611 - val_loss: 0.1283 - val_acc: 0.9591\n",
      "Epoch 10/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.1205 - acc: 0.9637 - val_loss: 0.1129 - val_acc: 0.9639\n",
      "Epoch 11/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.1136 - acc: 0.9653 - val_loss: 0.1080 - val_acc: 0.9660\n",
      "Epoch 12/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.1060 - acc: 0.9698 - val_loss: 0.1073 - val_acc: 0.9663\n",
      "Epoch 13/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.1002 - acc: 0.9702 - val_loss: 0.1031 - val_acc: 0.9657\n",
      "Epoch 14/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0938 - acc: 0.9719 - val_loss: 0.1031 - val_acc: 0.9630\n",
      "Epoch 15/36\n",
      "13296/13296 [==============================] - 1s 106us/step - loss: 0.0887 - acc: 0.9741 - val_loss: 0.0933 - val_acc: 0.9717\n",
      "Epoch 16/36\n",
      "13296/13296 [==============================] - 1s 109us/step - loss: 0.0841 - acc: 0.9747 - val_loss: 0.1074 - val_acc: 0.9660\n",
      "Epoch 17/36\n",
      "13296/13296 [==============================] - 1s 107us/step - loss: 0.0815 - acc: 0.9744 - val_loss: 0.0891 - val_acc: 0.9726\n",
      "Epoch 18/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0761 - acc: 0.9771 - val_loss: 0.0856 - val_acc: 0.9744\n",
      "Epoch 19/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0728 - acc: 0.9786 - val_loss: 0.0831 - val_acc: 0.9747\n",
      "Epoch 20/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0697 - acc: 0.9792 - val_loss: 0.0783 - val_acc: 0.9774\n",
      "Epoch 21/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0652 - acc: 0.9807 - val_loss: 0.0804 - val_acc: 0.9768\n",
      "Epoch 22/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0625 - acc: 0.9811 - val_loss: 0.0817 - val_acc: 0.9744\n",
      "Epoch 23/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0593 - acc: 0.9835 - val_loss: 0.0932 - val_acc: 0.9690\n",
      "Epoch 24/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0566 - acc: 0.9841 - val_loss: 0.0743 - val_acc: 0.9774\n",
      "Epoch 25/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0545 - acc: 0.9846 - val_loss: 0.0734 - val_acc: 0.9765\n",
      "Epoch 26/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0519 - acc: 0.9850 - val_loss: 0.0738 - val_acc: 0.9771\n",
      "Epoch 27/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0499 - acc: 0.9856 - val_loss: 0.0714 - val_acc: 0.9780\n",
      "Epoch 28/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0483 - acc: 0.9871 - val_loss: 0.0741 - val_acc: 0.9744\n",
      "Epoch 29/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0451 - acc: 0.9877 - val_loss: 0.0757 - val_acc: 0.9768\n",
      "Epoch 30/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0433 - acc: 0.9876 - val_loss: 0.0735 - val_acc: 0.9774\n",
      "Epoch 31/36\n",
      "13296/13296 [==============================] - 1s 104us/step - loss: 0.0420 - acc: 0.9882 - val_loss: 0.0759 - val_acc: 0.9744\n",
      "Epoch 32/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0401 - acc: 0.9889 - val_loss: 0.0805 - val_acc: 0.9741\n",
      "Epoch 33/36\n",
      "13296/13296 [==============================] - 1s 103us/step - loss: 0.0382 - acc: 0.9901 - val_loss: 0.0723 - val_acc: 0.9771\n",
      "Epoch 34/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0372 - acc: 0.9892 - val_loss: 0.0689 - val_acc: 0.9789\n",
      "Epoch 35/36\n",
      "13296/13296 [==============================] - 1s 104us/step - loss: 0.0347 - acc: 0.9904 - val_loss: 0.0808 - val_acc: 0.9735\n",
      "Epoch 36/36\n",
      "13296/13296 [==============================] - 1s 102us/step - loss: 0.0344 - acc: 0.9898 - val_loss: 0.0666 - val_acc: 0.9783\n",
      "Train on 15172 samples, validate on 3793 samples\n",
      "Epoch 1/31\n",
      "15172/15172 [==============================] - 2s 115us/step - loss: 1.0296 - acc: 0.6909 - val_loss: 0.4251 - val_acc: 0.8798\n",
      "Epoch 2/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.3157 - acc: 0.9076 - val_loss: 0.3347 - val_acc: 0.8953\n",
      "Epoch 3/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.2486 - acc: 0.9276 - val_loss: 0.2183 - val_acc: 0.9378\n",
      "Epoch 4/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.2179 - acc: 0.9369 - val_loss: 0.2053 - val_acc: 0.9409\n",
      "Epoch 5/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.1981 - acc: 0.9425 - val_loss: 0.1875 - val_acc: 0.9428\n",
      "Epoch 6/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.1814 - acc: 0.9480 - val_loss: 0.2704 - val_acc: 0.9241\n",
      "Epoch 7/31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1695 - acc: 0.9509 - val_loss: 0.1701 - val_acc: 0.9504\n",
      "Epoch 8/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1575 - acc: 0.9552 - val_loss: 0.1797 - val_acc: 0.9473\n",
      "Epoch 9/31\n",
      "15172/15172 [==============================] - 2s 101us/step - loss: 0.1480 - acc: 0.9582 - val_loss: 0.1615 - val_acc: 0.9483\n",
      "Epoch 10/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1411 - acc: 0.9596 - val_loss: 0.1467 - val_acc: 0.9578\n",
      "Epoch 11/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1327 - acc: 0.9607 - val_loss: 0.1502 - val_acc: 0.9562\n",
      "Epoch 12/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1249 - acc: 0.9648 - val_loss: 0.1329 - val_acc: 0.9594\n",
      "Epoch 13/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1190 - acc: 0.9659 - val_loss: 0.1402 - val_acc: 0.9565\n",
      "Epoch 14/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1132 - acc: 0.9674 - val_loss: 0.1283 - val_acc: 0.9612\n",
      "Epoch 15/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.1066 - acc: 0.9699 - val_loss: 0.1327 - val_acc: 0.9583\n",
      "Epoch 16/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.1026 - acc: 0.9717 - val_loss: 0.1259 - val_acc: 0.9610\n",
      "Epoch 17/31\n",
      "15172/15172 [==============================] - 2s 101us/step - loss: 0.0973 - acc: 0.9710 - val_loss: 0.1323 - val_acc: 0.9615\n",
      "Epoch 18/31\n",
      "15172/15172 [==============================] - 2s 107us/step - loss: 0.0926 - acc: 0.9742 - val_loss: 0.1199 - val_acc: 0.9634\n",
      "Epoch 19/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.0890 - acc: 0.9741 - val_loss: 0.1154 - val_acc: 0.9644\n",
      "Epoch 20/31\n",
      "15172/15172 [==============================] - 2s 107us/step - loss: 0.0838 - acc: 0.9765 - val_loss: 0.1157 - val_acc: 0.9657\n",
      "Epoch 21/31\n",
      "15172/15172 [==============================] - 2s 107us/step - loss: 0.0812 - acc: 0.9784 - val_loss: 0.1157 - val_acc: 0.9665\n",
      "Epoch 22/31\n",
      "15172/15172 [==============================] - 2s 102us/step - loss: 0.0762 - acc: 0.9780 - val_loss: 0.1103 - val_acc: 0.9681\n",
      "Epoch 23/31\n",
      "15172/15172 [==============================] - 2s 105us/step - loss: 0.0733 - acc: 0.9796 - val_loss: 0.1436 - val_acc: 0.9560\n",
      "Epoch 24/31\n",
      "15172/15172 [==============================] - 2s 108us/step - loss: 0.0702 - acc: 0.9806 - val_loss: 0.1206 - val_acc: 0.9618\n",
      "Epoch 25/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.0672 - acc: 0.9807 - val_loss: 0.1106 - val_acc: 0.9684\n",
      "Epoch 26/31\n",
      "15172/15172 [==============================] - 2s 104us/step - loss: 0.0641 - acc: 0.9825 - val_loss: 0.1067 - val_acc: 0.9692\n",
      "Epoch 27/31\n",
      "15172/15172 [==============================] - 2s 104us/step - loss: 0.0612 - acc: 0.9827 - val_loss: 0.1037 - val_acc: 0.9692\n",
      "Epoch 28/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.0586 - acc: 0.9832 - val_loss: 0.1096 - val_acc: 0.9684\n",
      "Epoch 29/31\n",
      "15172/15172 [==============================] - 2s 103us/step - loss: 0.0561 - acc: 0.9844 - val_loss: 0.1106 - val_acc: 0.9673\n",
      "Epoch 30/31\n",
      "15172/15172 [==============================] - 2s 105us/step - loss: 0.0537 - acc: 0.9842 - val_loss: 0.1010 - val_acc: 0.9707\n",
      "Epoch 31/31\n",
      " 8320/15172 [===============>..............] - ETA: 0s - loss: 0.0535 - acc: 0.9855"
     ]
    }
   ],
   "source": [
    "# Train whole, model1, model2, model3\n",
    "model_list = train_dataset(epoch_list, train_list, label_list, custom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model_list[0].save(model_dir + 'model_whole-0.0095LR.h5')\n",
    "model_list[1].save(model_dir + 'model1-0.0095LR.h5')\n",
    "model_list[2].save(model_dir + 'model2-0.0095LR.h5')\n",
    "model_list[3].save(model_dir + 'model3-0.0095LR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain accuracy parameters to print\n",
    "test_size, whole_acc, avg_ensemble_acc, max_ensemble_acc, model1_acc, model2_acc, model3_acc = accuracy_test(model_list, train_list[4], label_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Entire Dataset Acc: \" + str(whole_acc) + \"/\" + str(test_size) +\n",
    "  '\\nAvg Ensemble Acc: ' + str(avg_ensemble_acc) + \"/\" + str(test_size)+\n",
    "  '\\nMax Ensemble Acc: ' + str(max_ensemble_acc) + \"/\" + str(test_size)+\n",
    "  '\\nModel 1 Acc: ' + str(model1_acc) + \"/\" + str(test_size) +\n",
    "  '\\nModel 2 Acc: ' + str(model2_acc) + \"/\" + str(test_size) +\n",
    "  '\\nModel 3 Acc: ' + str(model3_acc) + \"/\" + str(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=test_x1, y=test_y1, verbose=1)\n",
    "model1.evaluate(x=test_x1, y=test_y1, verbose=1)\n",
    "model2.evaluate(x=test_x2, y=test_y2, verbose=1)\n",
    "model3.evaluate(x=test_x3, y=test_y3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model1.layers[0].get_weights()[0]\n",
    "biases = model1.layers[0].get_weights()[1]\n",
    "\n",
    "weights = model2.layers[0].get_weights()[0]\n",
    "biases = model2.layers[0].get_weights()[1]\n",
    "\n",
    "weights = model3.layers[0].get_weights()[0]\n",
    "biases = model3.layers[0].get_weights()[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
